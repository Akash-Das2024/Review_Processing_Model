{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QhSsIvzBKez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04392c34-7df1-463b-e45b-d5c2b7a834dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from textblob import TextBlob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# preprocessing the data\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    stemmer = PorterStemmer()\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    sentence = str(sentence)\n",
        "    # Tokenize the sentence\n",
        "    tokens = word_tokenize(sentence.lower())\n",
        "    \n",
        "    # Remove stop words\n",
        "    tokens = [token for token in tokens if token not in stop_words]\n",
        "    \n",
        "    # Stem each word\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "    \n",
        "    # Lemmatize each word\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in stemmed_tokens]\n",
        "    \n",
        "    # Join the tokens back into a sentence\n",
        "    cleaned_sentence = ' '.join(lemmatized_tokens)\n",
        "    \n",
        "    return cleaned_sentence\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reading the csv file \n",
        "\n",
        "df = pd.read_csv(\"Review2.csv\")\n",
        "print(df.head())\n",
        "print(\"Row Count: \")\n",
        "print(df.shape[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmlhgEHGC8Bp",
        "outputId": "d8298e53-8859-4d2d-b1c0-8f2bef1ae760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "Row Count: \n",
            "14075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocessing the data\n",
        "\n",
        "df = df[[\"review\", \"sentiment\"]]\n",
        "print(df.head())\n",
        "\n",
        "print(df[\"review\"].dtype)\n",
        "print(df[\"sentiment\"].unique())\n",
        "\n",
        "df[\"review\"] = df[\"review\"].apply(preprocess_sentence)\n",
        "\n",
        "print(\"Data after Preprocessing: \")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAfcqpa03fJK",
        "outputId": "d5d48dda-f33b-4696-943e-d55dc6d12854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              review sentiment\n",
            "0  One of the other reviewers has mentioned that ...  positive\n",
            "1  A wonderful little production. <br /><br />The...  positive\n",
            "2  I thought this was a wonderful way to spend ti...  positive\n",
            "3  Basically there's a family where a little boy ...  negative\n",
            "4  Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
            "object\n",
            "['positive' 'negative']\n",
            "Data after Preprocessing: \n",
            "                                              review sentiment\n",
            "0  one review mention watch 1 oz episod 'll hook ...  positive\n",
            "1  wonder littl product . < br / > < br / > film ...  positive\n",
            "2  thought wonder way spend time hot summer weeke...  positive\n",
            "3  basic 's famili littl boy ( jake ) think 's zo...  negative\n",
            "4  petter mattei 's `` love time money '' visual ...  positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using Baye's Model to Predict\n",
        "\n",
        "# dividing the data into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[\"review\"], df[\"sentiment\"], test_size=0.2, random_state=42)\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "print(\"X_train vectorized: \")\n",
        "print(X_train)\n",
        "\n",
        "X_test = vectorizer.transform(X_test)\n",
        "print(\"X_train vectorized: \")\n",
        "print(X_test)\n",
        "\n",
        "# Train a Naive Bayes classifier on the training data\n",
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the performance of the classifier on the testing data\n",
        "accuracy = nb.score(X_test, y_test)\n",
        "# precision = nb.score(X_test, y_test == 1)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "# print(\"Precision:\", precision)"
      ],
      "metadata": {
        "id": "SIT1ZyDl6cmS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33307b4d-af55-4b02-81dc-58516b8a343e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train vectorized: \n",
            "  (0, 31990)\t1\n",
            "  (0, 13398)\t3\n",
            "  (0, 20941)\t1\n",
            "  (0, 25476)\t1\n",
            "  (0, 4959)\t18\n",
            "  (0, 41005)\t1\n",
            "  (0, 38019)\t1\n",
            "  (0, 26234)\t2\n",
            "  (0, 21157)\t1\n",
            "  (0, 21378)\t1\n",
            "  (0, 30884)\t1\n",
            "  (0, 22425)\t1\n",
            "  (0, 14397)\t1\n",
            "  (0, 34331)\t1\n",
            "  (0, 27060)\t1\n",
            "  (0, 14031)\t1\n",
            "  (0, 17701)\t1\n",
            "  (0, 26097)\t1\n",
            "  (0, 30855)\t1\n",
            "  (0, 32629)\t1\n",
            "  (0, 13519)\t1\n",
            "  (0, 26170)\t1\n",
            "  (0, 34851)\t1\n",
            "  (0, 1756)\t2\n",
            "  (0, 8463)\t2\n",
            "  :\t:\n",
            "  (11259, 38931)\t1\n",
            "  (11259, 41103)\t1\n",
            "  (11259, 11129)\t1\n",
            "  (11259, 26885)\t1\n",
            "  (11259, 29214)\t4\n",
            "  (11259, 18776)\t1\n",
            "  (11259, 34648)\t1\n",
            "  (11259, 22182)\t1\n",
            "  (11259, 25561)\t1\n",
            "  (11259, 22362)\t1\n",
            "  (11259, 15608)\t1\n",
            "  (11259, 32840)\t1\n",
            "  (11259, 18329)\t1\n",
            "  (11259, 34321)\t1\n",
            "  (11259, 34939)\t1\n",
            "  (11259, 40060)\t1\n",
            "  (11259, 26662)\t1\n",
            "  (11259, 27610)\t1\n",
            "  (11259, 33286)\t1\n",
            "  (11259, 2289)\t1\n",
            "  (11259, 31612)\t1\n",
            "  (11259, 18230)\t1\n",
            "  (11259, 12594)\t1\n",
            "  (11259, 26566)\t1\n",
            "  (11259, 22697)\t1\n",
            "X_train vectorized: \n",
            "  (0, 2051)\t1\n",
            "  (0, 2530)\t1\n",
            "  (0, 4006)\t1\n",
            "  (0, 4123)\t1\n",
            "  (0, 4474)\t1\n",
            "  (0, 4959)\t8\n",
            "  (0, 6511)\t1\n",
            "  (0, 10358)\t3\n",
            "  (0, 12458)\t1\n",
            "  (0, 12556)\t1\n",
            "  (0, 13398)\t3\n",
            "  (0, 13942)\t1\n",
            "  (0, 14181)\t1\n",
            "  (0, 15713)\t1\n",
            "  (0, 15714)\t1\n",
            "  (0, 17069)\t1\n",
            "  (0, 17379)\t1\n",
            "  (0, 17732)\t1\n",
            "  (0, 18006)\t1\n",
            "  (0, 18116)\t1\n",
            "  (0, 18681)\t1\n",
            "  (0, 18706)\t1\n",
            "  (0, 19510)\t1\n",
            "  (0, 21471)\t1\n",
            "  (0, 21866)\t1\n",
            "  :\t:\n",
            "  (2814, 26234)\t3\n",
            "  (2814, 27474)\t2\n",
            "  (2814, 28111)\t1\n",
            "  (2814, 28190)\t1\n",
            "  (2814, 29961)\t1\n",
            "  (2814, 32017)\t1\n",
            "  (2814, 32525)\t1\n",
            "  (2814, 33193)\t1\n",
            "  (2814, 33311)\t1\n",
            "  (2814, 33977)\t1\n",
            "  (2814, 35079)\t1\n",
            "  (2814, 35467)\t2\n",
            "  (2814, 35908)\t1\n",
            "  (2814, 36464)\t1\n",
            "  (2814, 36873)\t1\n",
            "  (2814, 37101)\t2\n",
            "  (2814, 38383)\t1\n",
            "  (2814, 38530)\t1\n",
            "  (2814, 40167)\t2\n",
            "  (2814, 40356)\t1\n",
            "  (2814, 40683)\t1\n",
            "  (2814, 40912)\t2\n",
            "  (2814, 40963)\t1\n",
            "  (2814, 41017)\t1\n",
            "  (2814, 41027)\t1\n",
            "Accuracy: 0.8483126110124334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using my_model to predict the reviews\n",
        "\n",
        "# the method Used:  score = Summation of(1 + log(tf)) and then take the average\n",
        "df_working = df.head(1000)\n",
        "\n",
        "def basemodel(r):\n",
        "    rs = 42  + 2 * r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df_working['review'], df_working['sentiment'], test_size=0.2, random_state=rs)\n",
        "    # evaluting the vocabulary\n",
        "    vocab = set()\n",
        "    for sentence in X_train:\n",
        "        words = sentence.split()\n",
        "        for word in words:\n",
        "            vocab.add(word)\n",
        "\n",
        "    # Create a dictionary to store the count of each word in each class\n",
        "    # array of index = word for all labels\n",
        "    # count how many time a word occured in each labels\n",
        "\n",
        "    class_word_counts = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_word_counts[c] = {}\n",
        "        for word in vocab:\n",
        "            class_word_counts[c][word] = 0\n",
        "\n",
        "    # Count the number of occurrences of each word in each class\n",
        "    for i in range(len(X_train)):\n",
        "        words = X_train.iloc[i].split()\n",
        "        c = y_train.iloc[i]\n",
        "        for word in words:\n",
        "            class_word_counts[c][word] += 1\n",
        "\n",
        "    doc_freq = {}\n",
        "\n",
        "    for word in vocab:\n",
        "      doc_freq[word] = 0\n",
        "      for c in np.unique(y_train):\n",
        "        if class_word_counts[c][word] != 0:\n",
        "          doc_freq[word] += 1\n",
        "\n",
        "\n",
        "    # Compute the total count of words in each class\n",
        "    class_word_totals = {}\n",
        "    for c in np.unique(y_train):\n",
        "        class_word_totals[c] = sum(class_word_counts[c].values())\n",
        "\n",
        "    # Define a function to predict the class of a new text sample\n",
        "    def predict(text):\n",
        "        text = preprocess_sentence(text)\n",
        "        words = text.split()\n",
        "        probs = {}\n",
        "        avg_score = 0\n",
        "        for c in np.unique(y_train):\n",
        "            score = 0\n",
        "            for word in words:\n",
        "              if word in vocab:\n",
        "                if class_word_counts[c][word] != 0:\n",
        "                  score += (1 + np.log(class_word_counts[c][word]))\n",
        "                else:\n",
        "                  score += 0\n",
        "\n",
        "            probs[c] = score\n",
        "            avg_score += score\n",
        "        return max(probs, key=probs.get)\n",
        "\n",
        "    # Evaluate the performance of the classifier on the testing data\n",
        "    correct = 0\n",
        "    hate_correct = 0\n",
        "    for i in range(len(X_test)):\n",
        "        pred = predict(X_test.iloc[i])\n",
        "        if pred == y_test.iloc[i]:\n",
        "            correct += 1\n",
        "            if pred == 'negative':\n",
        "              hate_correct += 1\n",
        "    accuracy = correct / len(y_test)\n",
        "    precision = hate_correct / (len(y_test == 'negative'))\n",
        "    print(\"*************************************************\")\n",
        "    print(\"Test no: \", end=\"\")\n",
        "    print(r)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"precision:\", precision)\n",
        "    print(\"test size: \", len(y_test))\n",
        "    print(\"correct: \", correct)\n",
        "    print(\"Total negative Reviews:\", len(y_test == 'negative'))\n",
        "    print(\"detected negative Reviews:\", hate_correct)\n",
        "    print(\"*************************************************\")\n",
        "    return accuracy, precision\n",
        "\n",
        "\n",
        "avg_accuracy = 0\n",
        "avg_precision = 0\n",
        "for i in range(10):\n",
        "  accuracy, precision = basemodel(i)\n",
        "  avg_accuracy += accuracy\n",
        "  avg_precision += precision\n",
        "\n",
        "print(\"average accuracy:\", avg_accuracy / 10)\n",
        "print(\"average precision:\", avg_precision/ 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqING37L_l98",
        "outputId": "5c42250a-52d8-4a1d-9842-84ba63a8fb43"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*************************************************\n",
            "Test no: 0\n",
            "Accuracy: 0.805\n",
            "precision: 0.41\n",
            "test size:  200\n",
            "correct:  161\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 82\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 1\n",
            "Accuracy: 0.775\n",
            "precision: 0.385\n",
            "test size:  200\n",
            "correct:  155\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 77\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 2\n",
            "Accuracy: 0.72\n",
            "precision: 0.395\n",
            "test size:  200\n",
            "correct:  144\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 79\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 3\n",
            "Accuracy: 0.735\n",
            "precision: 0.35\n",
            "test size:  200\n",
            "correct:  147\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 70\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 4\n",
            "Accuracy: 0.69\n",
            "precision: 0.26\n",
            "test size:  200\n",
            "correct:  138\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 52\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 5\n",
            "Accuracy: 0.745\n",
            "precision: 0.38\n",
            "test size:  200\n",
            "correct:  149\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 76\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 6\n",
            "Accuracy: 0.79\n",
            "precision: 0.375\n",
            "test size:  200\n",
            "correct:  158\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 75\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 7\n",
            "Accuracy: 0.71\n",
            "precision: 0.445\n",
            "test size:  200\n",
            "correct:  142\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 89\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 8\n",
            "Accuracy: 0.785\n",
            "precision: 0.415\n",
            "test size:  200\n",
            "correct:  157\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 83\n",
            "*************************************************\n",
            "*************************************************\n",
            "Test no: 9\n",
            "Accuracy: 0.71\n",
            "precision: 0.27\n",
            "test size:  200\n",
            "correct:  142\n",
            "Total negative Reviews: 200\n",
            "detected negative Reviews: 54\n",
            "*************************************************\n",
            "average accuracy: 0.7464999999999999\n",
            "average precision: 0.3685\n"
          ]
        }
      ]
    }
  ]
}